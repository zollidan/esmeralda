import pika
import json
import logging
import uuid
from typing import Dict, Any
from config import get_settings
from parser.s3_uploader import S3Uploader
from parser.result_publisher import ResultPublisher
from worker.src.parser.core.temp_parser import parse_soccerway, parse_another_site

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
settings = get_settings()

logging.basicConfig(
    level=settings.app.log_level,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –°–ª–æ–≤–∞—Ä—å –ø–∞—Ä—Å–µ—Ä–æ–≤ - –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ
PARSERS = {
    'soccerway': parse_soccerway,
    'another_site': parse_another_site,
    # –î–æ–±–∞–≤–ª—è–π —Å–≤–æ–∏ –ø–∞—Ä—Å–µ—Ä—ã —Å—é–¥–∞
}


def process_task(task_data: Dict[str, Any], s3_uploader: S3Uploader, publisher: ResultPublisher):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏

    Args:
        task_data: –î–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ RabbitMQ
        s3_uploader: –≠–∫–∑–µ–º–ø–ª—è—Ä S3Uploader
        publisher: –≠–∫–∑–µ–º–ø–ª—è—Ä ResultPublisher
    """
    task_id = task_data.get('task_id', 'unknown')
    parser_id = task_data.get('parser_id', 'default')

    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ {task_id}, –ø–∞—Ä—Å–µ—Ä: {parser_id}")

    try:
        # 1. –ü–æ–ª—É—á–∞–µ–º –Ω—É–∂–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
        parser_func = PARSERS.get(parser_id)
        if not parser_func:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø–∞—Ä—Å–µ—Ä–∞: {parser_id}")

        # 2. –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥
        df = parser_func(task_data)

        if df is None or df.empty:
            raise ValueError("–ü–∞—Ä—Å–µ—Ä –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")

        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
        filename = f"{parser_id}-{task_id}-{uuid.uuid4()}.xlsx"

        # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3
        upload_result = s3_uploader.upload_dataframe(df, filename)

        # 5. –ü—É–±–ª–∏–∫—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        if upload_result['success']:
            publisher.publish_success(
                task_id=task_id,
                file_path=upload_result['path'],
                metadata={
                    'parser_id': parser_id,
                    'rows_count': len(df),
                    'columns': list(df.columns)
                }
            )
            logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        else:
            # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤ S3 –Ω–µ —É–¥–∞–ª–∞—Å—å - –ø—É–±–ª–∏–∫—É–µ–º –æ—à–∏–±–∫—É
            error_msg = upload_result.get(
                'error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3')
            publisher.publish_failure(
                task_id=task_id,
                error=error_msg,
                metadata={'parser_id': parser_id}
            )
            logger.error(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} –ø—Ä–æ–≤–∞–ª–µ–Ω–∞: {error_msg}")

    except Exception as e:
        # –õ—é–±–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ - –ø—É–±–ª–∏–∫—É–µ–º –≤ RabbitMQ
        error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏: {str(e)}"
        logger.exception(f"‚ùå –ó–∞–¥–∞—á–∞ {task_id} –ø—Ä–æ–≤–∞–ª–µ–Ω–∞ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º")

        publisher.publish_failure(
            task_id=task_id,
            error=error_msg,
            metadata={'parser_id': parser_id}
        )


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∑–∞–ø—É—Å–∫ consumer"""

    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ worker: {settings.app.worker_name}")
    logger.info(f"üìã –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {settings.app.log_level}")

    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è S3 uploader...")
    s3_uploader = S3Uploader(
        endpoint_url=settings.s3.endpoint_url,
        access_key=settings.s3.access_key,
        secret_key=settings.s3.secret_key,
        bucket_name=settings.s3.bucket_name
    )

    logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RabbitMQ...")
    credentials = pika.PlainCredentials(
        settings.rabbitmq.username,
        settings.rabbitmq.password
    )
    connection = pika.BlockingConnection(
        pika.ConnectionParameters(
            host=settings.rabbitmq.host,
            port=settings.rabbitmq.port,
            credentials=credentials
        )
    )
    channel = connection.channel()

    # –û–±—ä—è–≤–ª—è–µ–º –æ—á–µ—Ä–µ–¥—å –¥–ª—è –∑–∞–¥–∞—á
    channel.queue_declare(queue=settings.rabbitmq.tasks_queue, durable=True)

    # –°–æ–∑–¥–∞–µ–º publisher –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    publisher = ResultPublisher(channel, settings.rabbitmq.results_queue)

    def callback(ch, method, properties, body):
        """Callback –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –æ—á–µ—Ä–µ–¥–∏"""
        try:
            task_data = json.loads(body)
            process_task(task_data, s3_uploader, publisher)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        except Exception as e:
            logger.exception(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ callback: {e}")
        finally:
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–æ–æ–±—â–µ–Ω–∏—è
            ch.basic_ack(delivery_tag=method.delivery_tag)

    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º prefetch - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á
    channel.basic_qos(prefetch_count=settings.app.prefetch_count)

    # –ù–∞—á–∏–Ω–∞–µ–º —Å–ª—É—à–∞—Ç—å –æ—á–µ—Ä–µ–¥—å
    channel.basic_consume(
        queue=settings.rabbitmq.tasks_queue,
        on_message_callback=callback
    )

    logger.info(
        f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á –∏–∑ '{settings.rabbitmq.tasks_queue}' (prefetch: {settings.app.prefetch_count})...")

    try:
        channel.start_consuming()
    except KeyboardInterrupt:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ worker...")
        channel.stop_consuming()
    finally:
        connection.close()


if __name__ == '__main__':
    main()
